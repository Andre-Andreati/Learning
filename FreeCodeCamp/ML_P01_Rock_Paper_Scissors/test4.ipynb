{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible strategies:\n",
    "        -- Need to be observed to counter:\n",
    "\n",
    "- fixed sequence of 'n' moves\n",
    "        -- previous 'n'+1 moves\n",
    "\n",
    "- (opponent's / self's) last 'n'[0-10] moves\n",
    "        -- previous n moves\n",
    "\n",
    "- (opponent's / self's) most common move in the last 'n'[2-1000] matches\n",
    "        -- ...\n",
    "\n",
    "- (opponent's / self's) most common 'm-moves'[2-10] sequence in the last 'n'[2-1000] matches\n",
    "        -- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables:\n",
    "length = 10 #number of previous matches to analyze\n",
    "seq_size = range(2, 6) #sequence sizes to test\n",
    "matches_range = [5, 10] #number of previous matches to look for moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some functions that will be used in the main script ##\n",
    "\n",
    "#function for counting the number of occurences of a substring in a string\n",
    "def count_substring(s, sub):\n",
    "    # Initialize count to zero\n",
    "    cnt = 0\n",
    "\n",
    "    # Iterate through the string to check for the substring\n",
    "    for i in range(len(s) - len(sub) + 1):\n",
    "        if s[i:i + len(sub)] == sub:  # If substring matches, increment count\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPSRPS'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opponent_hist = \"RRRPPPSSS\" * 10\n",
    "player_hist = \"RPS\" * 30\n",
    "player_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_moves = sorted(['R', 'P', 'S'])\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab_moves)}\n",
    "idx2char = np.array(vocab_moves)\n",
    "\n",
    "def text_to_int(text):\n",
    "  return [char2idx[c] for c in text]\n",
    "\n",
    "def int_to_text(ints):\n",
    "  return ''.join(idx2char[ints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab of sequences with 2-5 elements\n",
    "vocab_seq = {}\n",
    "for i in seq_size:\n",
    "  vocab_seq[i] = []\n",
    "  for seq in it.product(vocab_moves, repeat=i):\n",
    "    vocab_seq[i].append(''.join(seq))\n",
    "\n",
    "#full vocabulary\n",
    "vocab = vocab_moves.copy()\n",
    "for i in seq_size:\n",
    "  for seq in it.product(vocab_moves, repeat=i):\n",
    "    vocab.append(''.join(seq))\n",
    "\n",
    "def int_encoding(text):\n",
    "  return vocab.index(text)\n",
    "\n",
    "def int_decoding(ints):\n",
    "  return vocab[ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crete a list with the last 'length' moves\n",
    "#of the opponent\n",
    "op_last_moves = {}\n",
    "for i in range(length):\n",
    "    op_last_moves[i] = []\n",
    "    for j in range(len(opponent_hist) - length):\n",
    "        op_last_moves[i].append(opponent_hist[i + j])\n",
    "\n",
    "#of the player\n",
    "pl_last_moves = {}\n",
    "for i in range(length):\n",
    "    pl_last_moves[i] = []\n",
    "    for j in range(len(player_hist) - length):\n",
    "        pl_last_moves[i].append(player_hist[i + j])\n",
    "\n",
    "#opponent_last_moves = [opponent_hist[i:i+length] for i in range(len(opponent_hist) - length)]\n",
    "#player_last_moves = [player_hist[i:i+length] for i in range(len(opponent_hist) - length)]\n",
    "#last_moves = opponent_last_moves + player_last_moves\n",
    "\n",
    "#op_last_moves[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list with the most common move in the last 'matches_range' matches, and in all matches\n",
    "#of the opponent\n",
    "op_commons = {}\n",
    "for i in matches_range:\n",
    "  op_commons[i] = []\n",
    "  for j in range(length, len(opponent_hist)):\n",
    "    op_commons[i].append(max(set(opponent_hist[j-i:j]), key=opponent_hist[j-i:j].count))\n",
    "op_commons['all'] = []\n",
    "for i in range(length, len(opponent_hist)):\n",
    "  op_commons['all'].append(max(set(opponent_hist[:i]), key=opponent_hist[:i].count))\n",
    "\n",
    "#of the player\n",
    "pl_commons = {}\n",
    "for i in matches_range:\n",
    "  pl_commons[i] = []\n",
    "  for j in range(length, len(opponent_hist)):\n",
    "    pl_commons[i].append(max(set(player_hist[j-i:j]), key=player_hist[j-i:j].count))\n",
    "pl_commons['all'] = []\n",
    "for i in range(length, len(opponent_hist)):\n",
    "  pl_commons['all'].append(max(set(player_hist[:i]), key=player_hist[:i].count))\n",
    "\n",
    "#op_commons['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list with the last sequence of 'seq_size' moves\n",
    "#of the opponent\n",
    "op_last_seqs = {}\n",
    "for i in seq_size:\n",
    "  op_last_seqs[i] = [opponent_hist[j-i:j] for j in range(length, len(opponent_hist))]\n",
    "\n",
    "#of the player\n",
    "pl_last_seqs = {}\n",
    "for i in seq_size:\n",
    "  pl_last_seqs[i] = [player_hist[j-i:j] for j in range(length, len(opponent_hist))]\n",
    "\n",
    "#op_last_seqs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list with the most common sequence of 'seq_size' moves in the last 'matches_range' matches\n",
    "#of the opponent\n",
    "op_common_seqs = {}\n",
    "\n",
    "for i in seq_size:\n",
    "    op_common_seqs[i] = {}\n",
    "    for j in matches_range:\n",
    "        op_common_seqs[i][j] = []\n",
    "        for k in range(length, len(opponent_hist)):\n",
    "            count_subs = {}\n",
    "            for seq in vocab_seq[i]:\n",
    "                count_subs[seq] = count_substring(opponent_hist[k-j:k], seq)\n",
    "            op_common_seqs[i][j].append(max(count_subs, key=count_subs.get))\n",
    "\n",
    "#of the player\n",
    "pl_common_seqs = {}\n",
    "\n",
    "for i in seq_size:\n",
    "    pl_common_seqs[i] = {}\n",
    "    for j in matches_range:\n",
    "        pl_common_seqs[i][j] = []\n",
    "        for k in range(length, len(opponent_hist)):\n",
    "            count_subs = {}\n",
    "            for seq in vocab_seq[i]:\n",
    "                count_subs[seq] = count_substring(player_hist[k-j:k], seq)\n",
    "            pl_common_seqs[i][j].append(max(count_subs, key=count_subs.get))\n",
    "\n",
    "#op_common_seqs[2][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list with the most common sequence of 'seq_size' moves in all matches\n",
    "#of the opponent\n",
    "op_common_seqs_all = {}\n",
    "\n",
    "for i in seq_size:\n",
    "    op_common_seqs_all[i] = []\n",
    "    for k in range(length, len(opponent_hist)):\n",
    "        count_subs = {}\n",
    "        for seq in vocab_seq[i]:\n",
    "            count_subs[seq] = count_substring(opponent_hist[:k], seq)\n",
    "        op_common_seqs_all[i].append(max(count_subs, key=count_subs.get))\n",
    "\n",
    "#of the player\n",
    "pl_common_seqs_all = {}\n",
    "\n",
    "for i in seq_size:\n",
    "    pl_common_seqs_all[i] = []\n",
    "    for k in range(length, len(opponent_hist)):\n",
    "        count_subs = {}\n",
    "        for seq in vocab_seq[i]:\n",
    "            count_subs[seq] = count_substring(player_hist[:k], seq)\n",
    "        pl_common_seqs_all[i].append(max(count_subs, key=count_subs.get))\n",
    "\n",
    "#op_common_seqs_all[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S'], ['R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P'], ['R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S'], ['P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S'], ['R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R'], ['S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R'], ['P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R'], ['R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P'], ['P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R'], ['P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S'], ['P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P'], ['S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R'], ['S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P'], ['R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P'], ['S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P'], ['P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S'], ['S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S'], ['S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R'], ['R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S'], ['R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P'], ['S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P'], ['R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R', 'P', 'R', 'R'], ['R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S', 'S', 'R', 'R', 'R', 'P', 'P', 'P', 'S', 'S'], ['R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P', 'S', 'R', 'P'], ['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R'], ['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R'], ['SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS', 'SS', 'SR', 'RR', 'RR', 'RP', 'PP', 'PP', 'PS', 'SS'], ['SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP'], ['SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS', 'SSS', 'SSR', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPS', 'PSS'], ['PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP', 'RPS', 'PSR', 'SRP'], ['SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS', 'PSSS', 'SSSR', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPSS'], ['RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP'], ['PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS'], ['SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP'], ['SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'SS', 'SS', 'SS', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP'], ['SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP', 'PS', 'SR', 'RP'], ['PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP', 'PP'], ['PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS', 'PS'], ['PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PSS', 'SRR', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP'], ['PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR', 'PSR'], ['PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPS', 'PPP', 'PPP', 'PPP'], ['PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR'], ['PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'SSRR', 'SRRR', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS'], ['RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP'], ['PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPSS', 'PSSS', 'PPPS', 'PPPS'], ['RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP', 'SRPS', 'RPSR', 'PSRP'], ['PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPSSS', 'PSSSR', 'SSSRR', 'SSRRR', 'SRRRP', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS'], ['SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP', 'PSRPS', 'SRPSR', 'RPSRP'], ['PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPSSS', 'PSSSR', 'RPPPS', 'PPPSS'], ['PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS', 'PSRPS'], ['PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP', 'PP', 'PP', 'RR', 'RR', 'RR', 'RR', 'PP', 'PP', 'PP'], ['PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP', 'PS', 'PS', 'RP'], ['PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'PPP', 'RRR', 'RRP', 'RPP', 'PPP', 'PPP', 'PPP'], ['PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR', 'RPS', 'PSR', 'PSR'], ['PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'PPPS', 'RRRP', 'RRPP', 'RPPP', 'PPPS', 'PPPS'], ['RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP', 'PSRP', 'RPSR', 'PSRP'], ['PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'PPPSS', 'RRRPP', 'RRPPP', 'RPPPS', 'PPPSS'], ['PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP', 'PSRPS', 'PSRPS', 'RPSRP']]\n"
     ]
    }
   ],
   "source": [
    "#join all previously defined features in a single list\n",
    "features = []\n",
    "for i in range(length):\n",
    "    features.append(op_last_moves[i])\n",
    "    features.append(pl_last_moves[i])\n",
    "for i in op_commons.keys():\n",
    "    features.append(op_commons[i])\n",
    "    features.append(pl_commons[i])\n",
    "for i in seq_size:\n",
    "    features.append(op_last_seqs[i])\n",
    "    features.append(pl_last_seqs[i])\n",
    "for i in op_common_seqs.keys():\n",
    "    for j in op_common_seqs[i].keys():\n",
    "        features.append(op_common_seqs[i][j])\n",
    "        features.append(pl_common_seqs[i][j])\n",
    "for i in op_common_seqs_all.keys():\n",
    "    features.append(op_common_seqs_all[i])\n",
    "    features.append(pl_common_seqs_all[i])\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of labels (correct next opponent's move on each match)\n",
    "labels = []\n",
    "for i in range(length, len(opponent_hist)):\n",
    "    labels.append(opponent_hist[i])\n",
    "\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 58),\n",
       " array([[  1,   1,   1, ...,  73, 128, 185],\n",
       "        [  1,   0,   1, ...,  60, 128, 222],\n",
       "        [  1,   2,   0, ...,  60, 128, 185],\n",
       "        ...,\n",
       "        [  0,   2,   2, ...,  60, 228, 185],\n",
       "        [  2,   1,   2, ...,  73, 203, 185],\n",
       "        [  2,   0,   2, ...,  60, 128, 222]]),\n",
       " (80,),\n",
       " array([1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 1, 0, 0,\n",
       "        0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2,\n",
       "        1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 1, 0,\n",
       "        0, 0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2]),\n",
       " array([  1,   1,   1,   0,   1,   2,   0,   1,   0,   0,   0,   2,   2,\n",
       "          1,   2,   0,   2,   2,   1,   1,   2,   1,   1,   1,   1,   1,\n",
       "         10,  10,  37,  19, 118,  73, 199, 316,  11,  10,   3,   5,  20,\n",
       "         19,  12,  19,  65,  73,  41,  73, 199, 316, 128, 185,   3,   5,\n",
       "         12,  19,  41,  73, 128, 185]),\n",
       " np.int64(1))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode the features and labels. Transpose because the LSTM model expects the input in the shape (batch, timesteps, feature)\n",
    "encoded_features = []\n",
    "for i in range(len(features)):\n",
    "    encoded_features.append([])\n",
    "    for j in range(len(features[i])):\n",
    "        encoded_features[i].append(int_encoding(features[i][j]))\n",
    "\n",
    "encoded_features_np = np.array(encoded_features).transpose()\n",
    "encoded_labels_np = np.array([int_encoding(label) for label in labels])\n",
    "\n",
    "encoded_features_np.shape, encoded_features_np, encoded_labels_np.shape, encoded_labels_np, encoded_features_np[0], encoded_labels_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([80, 58, 363]), TensorShape([80, 3]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encode the features and labels\n",
    "onehot_features = tf.one_hot(encoded_features_np, len(vocab))\n",
    "onehot_labels = tf.one_hot(encoded_labels_np, len(vocab_moves))\n",
    "onehot_features.shape, onehot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 725ms/step - Accuracy: 0.5469 - loss: 1.0755\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step - Accuracy: 0.4594 - loss: 0.9644\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730ms/step - Accuracy: 0.8031 - loss: 0.9104\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728ms/step - Accuracy: 0.8727 - loss: 0.7603\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718ms/step - Accuracy: 0.6031 - loss: 1.0221\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711ms/step - Accuracy: 0.8016 - loss: 0.7156\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712ms/step - Accuracy: 0.8570 - loss: 0.6003\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 812ms/step - Accuracy: 0.9031 - loss: 0.4204\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742ms/step - Accuracy: 0.9625 - loss: 0.3490\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721ms/step - Accuracy: 0.7766 - loss: 0.3483\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734ms/step - Accuracy: 0.7828 - loss: 0.3751\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802ms/step - Accuracy: 0.8719 - loss: 0.3514\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715ms/step - Accuracy: 1.0000 - loss: 0.2345\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - Accuracy: 1.0000 - loss: 0.2190\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718ms/step - Accuracy: 1.0000 - loss: 0.1232\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - Accuracy: 1.0000 - loss: 0.0888\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 0.0382\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736ms/step - Accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805ms/step - Accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 768ms/step - Accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 846ms/step - Accuracy: 1.0000 - loss: 9.2690e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 779ms/step - Accuracy: 1.0000 - loss: 3.6583e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782ms/step - Accuracy: 1.0000 - loss: 2.4500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 784ms/step - Accuracy: 1.0000 - loss: 1.8735e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739ms/step - Accuracy: 1.0000 - loss: 1.0780e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 789ms/step - Accuracy: 1.0000 - loss: 4.8908e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 770ms/step - Accuracy: 1.0000 - loss: 2.5601e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 771ms/step - Accuracy: 1.0000 - loss: 1.5129e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745ms/step - Accuracy: 1.0000 - loss: 9.7556e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745ms/step - Accuracy: 1.0000 - loss: 7.7701e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727ms/step - Accuracy: 1.0000 - loss: 5.8785e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 731ms/step - Accuracy: 1.0000 - loss: 5.3652e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782ms/step - Accuracy: 1.0000 - loss: 4.6763e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802ms/step - Accuracy: 1.0000 - loss: 4.1799e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 792ms/step - Accuracy: 1.0000 - loss: 3.8994e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757ms/step - Accuracy: 1.0000 - loss: 3.4245e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step - Accuracy: 1.0000 - loss: 3.6221e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 764ms/step - Accuracy: 1.0000 - loss: 3.5922e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 788ms/step - Accuracy: 1.0000 - loss: 3.3406e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757ms/step - Accuracy: 1.0000 - loss: 3.3163e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step - Accuracy: 1.0000 - loss: 3.5130e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790ms/step - Accuracy: 1.0000 - loss: 3.1408e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 774ms/step - Accuracy: 1.0000 - loss: 3.0494e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715ms/step - Accuracy: 1.0000 - loss: 3.2515e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step - Accuracy: 1.0000 - loss: 3.0601e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 3.0829e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754ms/step - Accuracy: 1.0000 - loss: 3.0670e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 791ms/step - Accuracy: 1.0000 - loss: 2.8051e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 784ms/step - Accuracy: 1.0000 - loss: 2.7200e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756ms/step - Accuracy: 1.0000 - loss: 2.8641e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753ms/step - Accuracy: 1.0000 - loss: 2.8370e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715ms/step - Accuracy: 1.0000 - loss: 3.0074e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 822ms/step - Accuracy: 1.0000 - loss: 2.7825e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729ms/step - Accuracy: 1.0000 - loss: 2.7825e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742ms/step - Accuracy: 1.0000 - loss: 2.7126e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 2.6173e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796ms/step - Accuracy: 1.0000 - loss: 2.7141e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711ms/step - Accuracy: 1.0000 - loss: 2.6852e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725ms/step - Accuracy: 1.0000 - loss: 2.4316e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719ms/step - Accuracy: 1.0000 - loss: 2.7127e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712ms/step - Accuracy: 1.0000 - loss: 2.6056e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 772ms/step - Accuracy: 1.0000 - loss: 2.5772e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785ms/step - Accuracy: 1.0000 - loss: 2.4899e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 782ms/step - Accuracy: 1.0000 - loss: 2.6108e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717ms/step - Accuracy: 1.0000 - loss: 2.4158e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724ms/step - Accuracy: 1.0000 - loss: 2.4023e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718ms/step - Accuracy: 1.0000 - loss: 2.4649e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 2.2048e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - Accuracy: 1.0000 - loss: 2.3543e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715ms/step - Accuracy: 1.0000 - loss: 2.0772e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - Accuracy: 1.0000 - loss: 2.3978e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - Accuracy: 1.0000 - loss: 2.2720e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730ms/step - Accuracy: 1.0000 - loss: 2.1377e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 2.1646e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711ms/step - Accuracy: 1.0000 - loss: 2.0881e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 2.2470e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712ms/step - Accuracy: 1.0000 - loss: 2.0294e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - Accuracy: 1.0000 - loss: 2.1490e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761ms/step - Accuracy: 1.0000 - loss: 2.1290e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736ms/step - Accuracy: 1.0000 - loss: 1.9561e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 726ms/step - Accuracy: 1.0000 - loss: 2.0551e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727ms/step - Accuracy: 1.0000 - loss: 2.0424e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739ms/step - Accuracy: 1.0000 - loss: 2.0475e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742ms/step - Accuracy: 1.0000 - loss: 1.8536e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 793ms/step - Accuracy: 1.0000 - loss: 1.8871e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 764ms/step - Accuracy: 1.0000 - loss: 1.7665e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733ms/step - Accuracy: 1.0000 - loss: 1.8662e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730ms/step - Accuracy: 1.0000 - loss: 1.8699e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760ms/step - Accuracy: 1.0000 - loss: 1.9795e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 766ms/step - Accuracy: 1.0000 - loss: 1.8187e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 784ms/step - Accuracy: 1.0000 - loss: 1.6773e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760ms/step - Accuracy: 1.0000 - loss: 1.7709e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730ms/step - Accuracy: 1.0000 - loss: 1.8023e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729ms/step - Accuracy: 1.0000 - loss: 1.6497e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760ms/step - Accuracy: 1.0000 - loss: 1.6394e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782ms/step - Accuracy: 1.0000 - loss: 1.7122e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758ms/step - Accuracy: 1.0000 - loss: 1.5730e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 784ms/step - Accuracy: 1.0000 - loss: 1.5550e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754ms/step - Accuracy: 1.0000 - loss: 1.7000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750ms/step - Accuracy: 1.0000 - loss: 1.5186e-06\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.LSTM(1024, input_shape=(onehot_features.shape[1], onehot_features.shape[2])),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(onehot_labels.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['Accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    onehot_features,\n",
    "    onehot_labels,\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('P', 0.93)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(opponent, player):\n",
    "    # input: opponent and player histories\n",
    "    # output: predicted output and it's probability\n",
    "    m = min(len(opponent), len(player)) #if the inputs have different lengths, 'm' is the smaller length,\n",
    "    seq = opponent[-m :] + player[-m :] #only use the last 'm' plays of each player\n",
    "    seq_encoded = np.array([text_to_int(seq)]) #encode sequence of chars into sequence of ints\n",
    "    seq_onehot = np.array([tf.keras.utils.to_categorical(se, num_classes=len(vocab)) for se in seq_encoded])\n",
    "        #encode sequence of ints into sequence of one-hots\n",
    "    pred = model.predict(seq_onehot) #run the prediction. Return list of probabilities for next char\n",
    "    idx = np.argmax(pred) #idx of the char with max probability, equal to the integer encoding for the chars\n",
    "    return int_to_text(idx), round(float(pred[0][idx]), 2) #predicted char, probability\n",
    "\n",
    "predict('RPS'*5, 'RPS'*5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
